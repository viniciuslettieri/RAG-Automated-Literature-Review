{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introdução"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Neste documento iniciamos a parte de recuperacao de documentos PDF partindo do suposto que temos uma base de arquivos PDF para utilizar.\n",
    "\n",
    "Neste preprocessamento, extraimos o texto dos pdfs para serem posteriormente processadas.\n",
    "\n",
    "Nossas etapas consistem em:\n",
    "\n",
    "* [Explicar etapas]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parte 0: Instalações"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install PyPDF2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parte 1: Listagem dos PDFs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf_folder_path = \"./parsed_pdf\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename_list = []\n",
    "for filename in os.listdir(pdf_folder_path):\n",
    "    if filename.endswith(\".txt\"):\n",
    "        filename_list.append(os.path.join(pdf_folder_path, filename))\n",
    "\n",
    "filename_list = sorted(filename_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['./parsed_pdf/documento_11422_10324.txt',\n",
       " './parsed_pdf/documento_11422_13409.txt',\n",
       " './parsed_pdf/documento_11422_14547.txt',\n",
       " './parsed_pdf/documento_11422_20921.txt',\n",
       " './parsed_pdf/documento_11422_21245.txt',\n",
       " './parsed_pdf/documento_11422_3776.txt',\n",
       " './parsed_pdf/documento_11422_4587.txt',\n",
       " './parsed_pdf/documento_11422_8763.txt']"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filename_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parte 2: Obtenção dos Metadados do Pantheon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata_folder_path = \"./metadados_pantheon\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename_metadata_list = []\n",
    "for filename in os.listdir(metadata_folder_path):\n",
    "    if filename.endswith(\".json\") and not filename.endswith(\"_x.json\"):\n",
    "        filename_metadata_list.append(os.path.join(metadata_folder_path, filename))\n",
    "\n",
    "filename_metadata_list = sorted(filename_metadata_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['./metadados_pantheon/documento_11422_10324.json',\n",
       " './metadados_pantheon/documento_11422_13409.json',\n",
       " './metadados_pantheon/documento_11422_14547.json',\n",
       " './metadados_pantheon/documento_11422_20921.json',\n",
       " './metadados_pantheon/documento_11422_21245.json',\n",
       " './metadados_pantheon/documento_11422_3776.json',\n",
       " './metadados_pantheon/documento_11422_4587.json',\n",
       " './metadados_pantheon/documento_11422_8763.json']"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filename_metadata_list "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata_dict = {}\n",
    "\n",
    "for filename in filename_metadata_list:\n",
    "    with open(filename) as f:\n",
    "        metadata = json.load(f)\n",
    "\n",
    "    _id = metadata[\"id\"]\n",
    "    \n",
    "    metadata_dict[_id] = metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "# metadata_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parte 3: Recuperação do arquivo txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_document(filename):\n",
    "    with open(filename, \"r\") as file:\n",
    "        file_text = file.read()\n",
    "    return file_text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " \n",
      "Análise da Relação dos Indicadores Lucro/Preço e Valor Contábil/Preço com o \n",
      "Retorno de Ações e Crescimento do Lucro das Empresas Brasileiras  \n",
      " \n",
      " \n",
      " \n",
      "RESUMO  \n",
      " \n",
      " \n",
      "As demonstrações contábeis são essenciais para precificar os ativos de uma \n",
      "empresa. Fama e French  (1992) demonstraram com modelos mu\n"
     ]
    }
   ],
   "source": [
    "full_text = retrieve_document(filename_list[0])\n",
    "print(full_text[:300])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parte 4: Tratamento do Texto em Blocos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Essa parte é importante porque os blocos precisam de um tamanho máximo de 4096 tokens para serem processados pelos modelos.\n",
    "* Não podemos simplesmente cortar os blocos na metade das frases.\n",
    "* Em muitos dos pdfs já estamos garantidos pelo \\n duplo, que deixa um espaço entre os parágrafos.\n",
    "* Mas em alguns o texto é muito fluido e não possui linhas vazias.\n",
    "* Também existe uma peculiaridade do PyPDF que ele não identifica texto corrido, então as linhas ficam quebradas exatamente na mudança de linha, o que nos impede de interpretar quebra de linha como mudança de parágrafo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Regras de Tratamento:**\n",
    "1. Quebra de blocos por saltos de linha duplicados, indicando a quebra de um parágrafo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextParser:\n",
    "    \n",
    "    TOKEN_CTX_SIZE = 1000\n",
    "    \n",
    "    def parse_paragraph(self, text: str) -> list:\n",
    "        text_split = text.split()\n",
    "        if len(text_split) < self.TOKEN_CTX_SIZE:\n",
    "            return [text]\n",
    "        else:\n",
    "            return text.split('.')\n",
    "\n",
    "    def join_paragraphs(self, text_pieces: list) -> list:\n",
    "        \"\"\"Joins text pieces limiting by the TOKEN_CTX_SIZE\"\"\"\n",
    "\n",
    "        final_text_pieces = []\n",
    "        \n",
    "        current_token_size = 0\n",
    "        current_text = \"\"\n",
    "        for piece in text_pieces:\n",
    "            piece_tokens = piece.split()\n",
    "                        \n",
    "            if current_token_size + len(piece_tokens) > self.TOKEN_CTX_SIZE:\n",
    "                final_text_pieces.append(current_text)\n",
    "                current_token_size = 0\n",
    "                current_text = \"\"\n",
    "                \n",
    "            current_token_size += len(piece_tokens)\n",
    "            current_text += piece + \"\\n\"                \n",
    "\n",
    "        final_text_pieces.append(current_text)\n",
    "        \n",
    "        return final_text_pieces\n",
    "    \n",
    "    def parse_full_text(self, full_text: str):\n",
    "        parsed_text = []\n",
    "        \n",
    "        for text in re.split(r'\\n[ \\t]+\\n', full_text):\n",
    "            blocks = self.parse_paragraph(text)\n",
    "            parsed_text.extend(blocks)\n",
    "\n",
    "        joined_pieces = self.join_paragraphs(parsed_text)\n",
    "\n",
    "        return joined_pieces"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Teste:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_parser = TextParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "parsed_text = text_parser.parse_full_text(full_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[5214, 5488, 5985, 6243, 5890, 5580, 5327, 5950, 6549, 322]"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[len(t) for t in parsed_text]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Análise da Relação dos Indicadores Lucro/Preço e Valor Contábil/Preço com o \n",
      "Retorno de Ações e Crescimento do Lucro das Empresas Brasileiras  \n",
      " \n",
      "RESUMO  \n",
      " \n",
      "As demonstrações contábeis são essenciais para precificar os ativos de uma \n",
      "empresa. Fama e French  (1992) demonstraram com modelos multifatoriais \n",
      "que o tamanho e o valor contábil do patrimônio líquido e preço de mercado \n",
      "(B/P) são importantes para explicar os retornos das ações. Penman et al. \n",
      "(2018) mostraram que as variáveis desalavancadas e a alavanca gem \n",
      "financeira explicaram os retornos. O objetivo dessa dissertação é estudar a \n",
      "relação entre as variáveis contábeis e de mercado com o crescimento dos \n",
      "lucros e retorno das ações, bem como a relação entre a alavancagem \n",
      "financeira e as variáveis desalavanca das com o retorno das ações. Foi \n",
      "realizado um estudo cross -section  com dados de 161 ações de empresas \n",
      "dos índices IBRX100 e small caps da bolsa Brasileira, coletados durante o \n",
      "período de 2011 a 201 6. A regressão linear foi utilizada em três análises \n",
      "para r elacionar as variáveis dependentes (crescimento dos lucros e \n",
      "retornos) com as variáveis preditoras (B/P, indicador lucro/preço E/P, \n",
      "tamanho, beta de mercado e variáveis desalavancadas). Os resultados \n",
      "indicam que o crescimento dos lucros possui uma relação positiva e \n",
      "significativa com E/P. O retorno das ações apresentou uma relação negativa \n",
      "com B/P e B/P desalavancado, e uma relação positiva com E/P e tamanho \n",
      "desalancados. A alavancagem financeira não apresentou resultados \n",
      "significativos para explicar o cres cimento dos lucros e o retorno das ações.  \n",
      "Palavras -chave : Modelo de precificação de ativos, variáveis \n",
      "desalavancadas, variáveis contábeis, mercado brasileiro.  \n",
      "7 \n",
      "ABSTRACT  \n",
      " \n",
      "Financial statements are essential for asset  pricing of a company. Fama  and \n",
      "French (1992) have demonstrated with multifactorial models that size and \n",
      "book -to-market (B/P) explain stock returns. Penman et al. (2018) suggested \n",
      "that the unlevered variables and financial leverage explained stock returns. \n",
      "The objective of this diss ertation is to study the relationship between the \n",
      "accounting and market variables with the earnings growth and stock returns, \n",
      "as well as the relationship between financial leverage and unlevered variables \n",
      "with stock returns. I perform a cross -section study  with 161 shares of \n",
      "companies from IBRX100 and small caps indexes in the Brazilian stock \n",
      "exchange collected during the period from 2011 to 201 6. Three analyzes were \n",
      "performed using linear regression to relate the dependent variables (earnings \n",
      "growth and re turns) with predictor variables (B/P, earnings/price E/P, size, \n",
      "market beta and unlevered variables). Our results indicated that earnings \n",
      "growth presented a positive relation with E/P. Moreover, stock returns had a \n",
      "negative relation with B/P and unlevered B/P, and a positive relation with \n",
      "unlevered E/P and size. Financial leverage did not present significant results \n",
      "to explain earnings growth and stock returns.  \n",
      "Keywords: Asset pricing model, unlevered variables, accounting \n",
      "variables, Brazilian market.  \n",
      " \n",
      "\n",
      "1. Introdução  \n",
      "As demonstrações contábeis são insumos essenciais para precificar os \n",
      "ativos de uma empresa. A Demonstração do Resultado do Exercício, o Balanço \n",
      "Patrimonial e a Demonstração do Fluxo de Caixa fornecem a mensuração do \n",
      "lucro e reportam a posição e evolução pa trimonial de uma empresa durante um \n",
      "determinado período. Diversos estudos discutiram precificação de ativos. \n",
      "Sharpe (1964) e Lintner (1965) foram os pioneiros nesta área de pesquisa ao \n",
      "desenvolver o Capital Asset Pricing Model (CAPM). Esse modelo mostra o \n",
      "retorno que os acionistas esperam obter por terem injetado dinheiro na \n",
      "companhia  (SHARPE, 1964) . \n",
      " Fama e French (1992) mostraram que o tamanho da empresa e a razão \n",
      "entre o valor contábil do patrimônio líquido  e o valor de mercado (B/P) explicam \n",
      "os retornos  das ações, diminuindo a relevância do beta de mercado. Fama e \n",
      "French (1992) afirmaram que, em seu modelo, o B/P absorve o efeito da \n",
      "alavancagem financeira e que o tamanho captura o efeito do indicador \n",
      "lucro/preço (E/P). O modelo multifatorial dos autores mostra que duas variáveis \n",
      "de risco adicionadas ao CAPM podem ser usadas como tentativa de conciliação \n",
      "com a teoria de precificação nos ativos.   \n",
      "Penman, Richardson e Tuna (2007) estudaram o comportamento do B/P \n",
      "em relação à alavancagem financeira e dividir am contabilmente o B/P, criando \n",
      "uma segregação dos componentes em atividades operacionais e atividades \n",
      "financeiras da empresa.  \n",
      "Penman et al. (2018) sugeriram que as variáveis desalavancadas e a \n",
      "alavancagem financeira poderiam explicar melhor os retornos q uando \n",
      "comparado ao modelo de Fama e French (1992), o que justificava essa \n",
      "segregação de componentes. Analisando o s resultados de Penman et al. \n",
      "(2018) e as considerações de Doshi et al (2019), as alavancagens podem gerar \n",
      "oportunidades  de obter retorno.  \n",
      "Esta pesquisa estuda a relação entre as variáveis contábeis e de \n",
      "mercado com o crescimento dos lucros e os retornos das ações. Além disso, \n",
      "estuda a relação entre a alavancagem financeira e as variáveis desalavancadas \n",
      "com o retorno das ações.  \n",
      "11 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(parsed_text[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parte 5: Refinamento da Formatação dos Blocos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Llama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from langchain.chains.llm import LLMChain\n",
    "# from langchain.prompts import PromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from langchain.llms import LlamaCpp\n",
    "# from langchain.callbacks.manager import CallbackManager\n",
    "# from langchain.callbacks.streaming_stdout import StreamingStdOutCallbackHandler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "# n_gpu_layers = 50  # Change this value based on your model and your GPU VRAM pool.\n",
    "# n_batch = 2000  # Should be between 1 and n_ctx, consider the amount of VRAM in your GPU.\n",
    "# callback_manager = CallbackManager([StreamingStdOutCallbackHandler()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# llm = LlamaCpp(\n",
    "#     model_path=\"/home/vinic/Projeto Final UFRJ/Arquivos Gerais/llama-2-13b-chat.Q5_K_M.gguf\",\n",
    "#     n_gpu_layers=n_gpu_layers,\n",
    "#     n_batch=n_batch,\n",
    "#     temperature=0.1,\n",
    "#     n_ctx=2000,\n",
    "#     max_tokens=2000,\n",
    "#     top_p=1,\n",
    "#     echo=False,\n",
    "#     f16_kv=True,  # MUST set to True, otherwise you will run into problem after a couple of calls\n",
    "#     callback_manager=callback_manager,\n",
    "#     # verbose=True,\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "# template = \"\"\"\n",
    "# '''\n",
    "# {doc}\n",
    "# '''\n",
    "\n",
    "# O texto anterior foi extraído de um documento e pode conter formatações indevidas, como quebras entre palavras e quebras de linhas.\n",
    "# Reescreva o texto como o original, apenas corrigindo os erros de formatação:\n",
    "# \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "# template = \"\"\"\n",
    "# O seguinte texto possui alguns erros de formatação, como quebras entre palavras e quebras de linhas indevidas:\n",
    "\n",
    "# '''{doc}'''\n",
    "\n",
    "# Escreva o texto novamente por completo, com o conteúdo igual ao original, mas corrigindo a formatação.\n",
    "# Mantenha a língua do texto original.\n",
    "# TEXTO CORRIGIDO:\n",
    "# \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "# template = \"\"\"\n",
    "# ### Instrução:\n",
    "# O texto de entrada foi extraído de um documento PDF e está mal formatado.\n",
    "# Reescreva o texto mantendo o conteúdo original mas com uma formatação melhor.\n",
    "# Não omita nenhuma informação do texto e use a mesma língua do original.\n",
    "\n",
    "# ### Entrada:\n",
    "# {doc}\n",
    "\n",
    "# ### Resposta:\n",
    "# \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "# template = \"\"\"\n",
    "# {doc}\n",
    "\n",
    "# Reformate o texto anterior mantendo seu conteúdo e em português:\n",
    "# \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "# template = \"\"\"\n",
    "# '''\n",
    "# {doc}\n",
    "# '''\n",
    "\n",
    "# O texto acima é um trecho de um documento e está mal formatado.\n",
    "# Apenas reescreva o texto com o mesmo conteúdo, corrigindo a formatação e mantenha a língua como português.\n",
    "# Resposta:\n",
    "# \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "# template = \"\"\"\n",
    "# O texto a seguir, dentro dos separadores ###, foi extraído de um documento pdf e contém alguns problemas de formatação e informações de rodapé inseridas indevidamente no meio do texto. Sua tarefa é reescrever esse mesmo texto, mantendo o conteúdo original, mas tratando esses problemas de formatação, como quebras de linhas indevidas durante o texto do parágrafo, quebra de palavras, e partes do rodapé inseridas indevidamente no meio do texto.\n",
    "\n",
    "# ###\n",
    "# {doc}\n",
    "# ###\n",
    "\n",
    "# Responda apenas com o texto corrido e corrigido, mantendo a mesma língua e palavras do texto original!\n",
    "# Não faça resumos e nem pressuponha textos, precisa ser verídico ao texto original!\n",
    "# Texto Corrigido:\n",
    "# \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "# template = \"\"\"\n",
    "# {doc}\n",
    "\n",
    "# O texto acima foi extraído de um documento pdf e contém alguns problemas de formatação e informações de rodapé inseridas indevidamente no meio do texto. Sua tarefa é reescrever esse mesmo texto, mantendo o conteúdo original, mas tratando esses problemas de formatação, como quebras de linhas indevidas durante o texto do parágrafo, quebra de palavras, e partes do rodapé inseridas indevidamente no meio do texto.\n",
    "# Responda apenas com o texto corrido e corrigido, mantendo a mesma língua e palavras do texto original!\n",
    "# Não faça resumos e nem pressuponha textos, precisa ser verídico ao texto original!\n",
    "# Texto Corrigido:\n",
    "# \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prompt = PromptTemplate.from_template(template)\n",
    "# chain = LLMChain(llm=llm, prompt=prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Formatação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(' '.join(re.split(r'[ \\t\\n]+', parsed_text[0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# print(parsed_text[0][500:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# chain.run(parsed_text[0][800:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GPT-3.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "openai_api_key = \"xxxxxxx\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.prompts.chat import (\n",
    "    ChatPromptTemplate,\n",
    "    HumanMessagePromptTemplate,\n",
    "    SystemMessagePromptTemplate,\n",
    ")\n",
    "from langchain.schema import HumanMessage, SystemMessage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "chat = ChatOpenAI(\n",
    "    model_name='gpt-3.5-turbo-16k',\n",
    "    temperature = 0.0,\n",
    "    openai_api_key = openai_api_key,         \n",
    "    max_tokens=6000\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextFormatter:\n",
    "    template = \"\"\"\n",
    "    O texto passado pelo usuário foi extraído de um documento pdf e contém alguns problemas de formatação e informações de rodapé inseridas indevidamente no meio do texto. \n",
    "    Sua tarefa é reescrever esse mesmo texto, mantendo o conteúdo original, mas tratando esses problemas de formatação, como quebras de linhas indevidas durante o texto do parágrafo, quebra de palavras, e partes do rodapé inseridas indevidamente no meio do texto.\n",
    "    Responda apenas com o texto corrido e corrigido, mantendo a mesma língua e palavras do texto original!\n",
    "    Não faça resumos e nem pressuponha textos, precisa ser verídico ao texto original!\n",
    "    \"\"\"\n",
    "    system_message_prompt = SystemMessagePromptTemplate.from_template(template)\n",
    "    \n",
    "    human_template = \"{text}\"\n",
    "    human_message_prompt = HumanMessagePromptTemplate.from_template(human_template)\n",
    "\n",
    "    chat_prompt = ChatPromptTemplate.from_messages(\n",
    "        [system_message_prompt, human_message_prompt]\n",
    "    )\n",
    "\n",
    "    def format_text(self, text_sections):\n",
    "        paragraphs = []\n",
    "        \n",
    "        print(\"Formatting Text: \", end=\"\")\n",
    "        \n",
    "        for text in text_sections:\n",
    "            print(\".\", end=\"\")\n",
    "            \n",
    "            fixed_text = chat(self.chat_prompt.format_prompt(text=text).to_messages()).content\n",
    "            fixed_paragraphs = fixed_text.split('\\n')\n",
    "            paragraphs.extend(fixed_paragraphs)\n",
    "\n",
    "        paragraphs = [p for p in paragraphs if p != '']\n",
    "\n",
    "        print(\" finished!\")\n",
    "        \n",
    "        return paragraphs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parte 6: Processamento Completo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_parser = TextParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "text_formatter = TextFormatter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_json = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "formatted_documents_path = \"./formatted_documents\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11422-4587\n",
      "Astrometria, efemérides e ocultações estelares de satélites irregulares e corpos do sistema solar exterior \n",
      "\n",
      "Formatting Text: ............."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised Timeout: Request timed out: HTTPSConnectionPool(host='api.openai.com', port=443): Read timed out. (read timeout=600).\n",
      "Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised Timeout: Request timed out: HTTPSConnectionPool(host='api.openai.com', port=443): Read timed out. (read timeout=600).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised Timeout: Request timed out: HTTPSConnectionPool(host='api.openai.com', port=443): Read timed out. (read timeout=600).\n",
      "Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised Timeout: Request timed out: HTTPSConnectionPool(host='api.openai.com', port=443): Read timed out. (read timeout=600).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".........."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised Timeout: Request timed out: HTTPSConnectionPool(host='api.openai.com', port=443): Read timed out. (read timeout=600).\n",
      "Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised Timeout: Request timed out: HTTPSConnectionPool(host='api.openai.com', port=443): Read timed out. (read timeout=600).\n",
      "Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised Timeout: Request timed out: HTTPSConnectionPool(host='api.openai.com', port=443): Read timed out. (read timeout=600).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised Timeout: Request timed out: HTTPSConnectionPool(host='api.openai.com', port=443): Read timed out. (read timeout=600).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "....... finished!\n",
      "11422-8763\n",
      "Avaliação clínico e laboratorial das mães dos meninos com distrofia muscular de Duchenne \n",
      "\n",
      "Formatting Text: ......... finished!\n"
     ]
    }
   ],
   "source": [
    "for filename in filename_list:\n",
    "    _filename = filename.split('/')[-1].split('.')[0]\n",
    "    _id = \"-\".join(_filename.split('_')[-2:])\n",
    "    _id_underscore = \"_\".join(_filename.split('_')[-2:])\n",
    "    \n",
    "    _metadata = metadata_dict[_id]\n",
    "    \n",
    "    print(_id)\n",
    "    print(_metadata[\"titulo\"], \"\\n\")\n",
    "\n",
    "    # document retrieval\n",
    "    document = retrieve_document(filename)\n",
    "\n",
    "    # parse document - break in blocks\n",
    "    parsed_text = text_parser.parse_full_text(document)\n",
    "    \n",
    "    # format document\n",
    "    formatted_text = text_formatter.format_text(parsed_text)\n",
    "\n",
    "    final_json[_id] = {\n",
    "        **_metadata,\n",
    "        \"sentences\": formatted_text\n",
    "    }\n",
    "\n",
    "    with open(f'{formatted_documents_path}/documento_' + _id_underscore + \".json\", 'w', encoding='utf-8') as f:\n",
    "        json.dump(final_json[_id], f, ensure_ascii=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llama",
   "language": "python",
   "name": "llama"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
