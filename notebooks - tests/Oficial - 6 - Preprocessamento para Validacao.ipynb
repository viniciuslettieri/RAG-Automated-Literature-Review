{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introdução"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Neste documento faremos o preprocessamento dos textos para criar os casos testes e salvá-los. Dessa forma, poderemos retestar sem aleatoriedade de eventos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install langchain==0.0.340 langchain --force-reinstall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_tests_partition = str(date.today())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'./validation_tests/2024-06-09'"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validation_tests_path = f'./validation_tests/{validation_tests_partition}'\n",
    "validation_tests_path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Recuperação dos Documentos Formatados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf_folder_path = \"./formatted_documents\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename_list = []\n",
    "for filename in os.listdir(pdf_folder_path):\n",
    "    if filename.endswith(\".json\"):\n",
    "        filename_list.append(os.path.join(pdf_folder_path, filename))\n",
    "\n",
    "filename_list = sorted(filename_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1538"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(filename_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_document(filename):\n",
    "    with open(filename, \"r\") as file:\n",
    "        json_file = json.load(file)\n",
    "    return json_file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_document = retrieve_document(filename_list[10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['title', 'authors', 'abstract', 'bibliography_pages', 'keywords', 'urls', 'pdf_url', 'id', 'sentences'])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "json_document.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'O lugar dos homens na natureza social : uma proposta reflexiva sobre o meio ambiente'"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "json_document['title']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Bessa, Eliane da Silva.',\n",
       " 'Randolph, Rainer orient.',\n",
       " 'Universidade Federal do Rio de Janeiro. Instituto de Pesquisa e Planejamento Urbano e Regional.']"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "json_document['authors']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Focaliza o meio ambiente como objeto de estudo. Parte da sua problematização como questão social para chegar à definição de uma proposta teórico-metodológica, cujo objetivo é entender o meio ambiente como forma particular de organização do território. O percurso que vincula um ponto ao outro passa, ...'"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "json_document['abstract'][:300] + '...'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Meio ambiente.', 'Conflito social.', 'Organização territorial.']"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "json_document['keywords']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['http://objdig.ufrj.br/42/teses/81683.pdf']"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "json_document['urls']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "print(len(json_document[\"sentences\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Seleção dos Testes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Escolha dos Testes:**\n",
    "\n",
    "1. Utilizaremos uma fração de 1000 abstracts dos artigos como input original.\n",
    "2. Obteremos os 4 abstracts mais similares a cada um destes via embedding.\n",
    "3. Para cada abstract original, utilizaremos uma LLM para sumarizar o tópico/tema de pesquisa."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reescrita com LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.schema import SystemMessage\n",
    "from langchain.chat_models import ChatOpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "openai_api_key = \"xxxxxxx\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(\n",
    "    model_name=\"gpt-3.5-turbo-0125\",\n",
    "    temperature=1,\n",
    "    # temperature=0.2,\n",
    "    openai_api_key=openai_api_key,       \n",
    "    max_tokens=4096\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_research_topic(title, abstract):\n",
    "#     query = f\"\"\"\n",
    "#         Dado o seguinte título e resumo de um artigo científico, sua tarefa é retornar o tópico central da pesquisa.\n",
    "        \n",
    "#         [TITULO] {title}\n",
    "#         [RESUMO] {abstract}\n",
    "        \n",
    "#         Qual o tópico central da pesquisa? Ou seja, o que busca-se pesquisar?\n",
    "#         Não retorne descobertas, conclusões ou qualquer tarefa que tenha sido realizado pela pesquisa, apenas o tópico de pesquisa.\n",
    "#         Não inicie com \"O tópico central da pesquisa é...\", vá direto ao ponto.\n",
    "#         Responda com no mínimo 40 palavras e no máximo 80 palavras.\n",
    "#     \"\"\"\n",
    "    \n",
    "#     messages = [SystemMessage(content=query)]\n",
    "#     response = llm(messages).content\n",
    "#     return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_research_topic(title, abstract):\n",
    "#     query = f\"\"\"\n",
    "#         Você é um pesquisador que está buscando realizar uma revisão de literatura sobre a nova pesquisa que está desenvolvendo. Esse é um resumo da nova pesquisa:\n",
    "#         \"{abstract}\"\n",
    "        \n",
    "#         Instruções:\n",
    "#         Identifique qual o objeto de pesquisa, ou seja, seu objetivo de estudo, e resuma.\n",
    "#         Não responda conclusões, descobertas ou o que foi feito na pesquisa, apenas é do interesse o tópico de pesquisa.\n",
    "#         Não inicie com \"O tópico central da pesquisa é...\", vá direto ao ponto.\n",
    "#         Retorne o resumo sobre o tópico de pesquisa com no mínimo 40 palavras e no máximo 80 palavras:\n",
    "#     \"\"\"\n",
    "    \n",
    "#     messages = [SystemMessage(content=query)]\n",
    "#     response = llm(messages).content\n",
    "#     return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_research_topic(title, abstract):\n",
    "#     query = f\"\"\"\n",
    "#         Você é um pesquisador que está buscando realizar uma revisão de literatura sobre a nova pesquisa que está desenvolvendo. Esse é um resumo da nova pesquisa:\n",
    "#         \"{abstract}\"\n",
    "        \n",
    "#         Instruções:\n",
    "#         Identifique qual o objetivo da pesquisa e resuma.\n",
    "#         Atenção, não é relevante conclusões, descobertas ou dizer o que foi realizado, queremos apenas o objetivo inicial da pesquisa.\n",
    "#         Retorne o resumo do objetivo com mínimo de 40 palavras e máximo 80 palavras:\n",
    "#     \"\"\"\n",
    "\n",
    "    # teste do joao\n",
    "    query = f\"\"\"\n",
    "        Você é um pesquisador que está buscando realizar uma revisão de literatura sobre a nova pesquisa que está desenvolvendo. Esse é um resumo da nova pesquisa:\n",
    "        \"{abstract}\"\n",
    "        \n",
    "        Instruções:\n",
    "        Qual o objetivo inicial da pesquisa? Resuma com mínimo de 40 palavras e máximo 80 palavras:\n",
    "    \"\"\"\n",
    "    \n",
    "    messages = [SystemMessage(content=query)]\n",
    "    response = llm(messages).content\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Acolhimento do Centro de Doença de Alzheimer do IPUB–UFRJ para idosos e seus cuidadores \n",
      "\n",
      "Abstract:  Centro de Doença de Alzheimer do IPUB é referência no atendimento de idosos com demência, no Rio de Janeiro. A enfermeira e a assistente social do setor criaram conjuntamente o serviço de acolhimento, para avaliação de novos usuários. Objetivo geral: Descrever a intervenção da enfermeira no acolhimento do CDA. Objetivos específicos: Apontar demandas em atenção psicossocial e psicogeriátrica dos usuários; Produzir materiais que inspirem possibilidades de atenção psicossocial a idosos em outros serviços de saúde mental. Como produto de contribuição técnica foi elaborado o fluxograma do serviço de acolhimento do CDA. A metodologia adotada foi o estudo de caso descritivo. Trata-se de uma pesquisa qualitativa, utilizando-se o instrumento de anamnese do serviço e um condensado de observações do campo de prática como fonte de dados. Em seu bojo são apresentados o percurso histórico do desenvolvimento do serviço, os níveis de proficiência da enfermeira e suas funções sociais exercidas na prática. Os participantes (N=79) foi a de idosos com idade ≥ 60 anos, sendo os casos com idade inferior a esta inseridos quando apresentavam queixas cognitivas e comportamentais. O estudo seguiu recomendações da Resolução 466 12/12/2012 do Conselho Nacional de Saúde, sobre Pesquisa com Seres Humanos. A análise dos dados compreendeu um estudo sociodemográfico, evidências de problemas psicogeriátricos e psicossociais dos usuários, tipo de vínculo dos acompanhantes, evidências que dificultam a implementação dos cuidados e as ações da enfermeira durante a consulta de acolhimento. As considerações finais discorrem sobre a importância da atuação do serviço junto a Política de Humanização. \n",
      "\n",
      "Query: O objetivo inicial da pesquisa é descrever a intervenção da enfermeira no acolhimento de idosos com demência no Centro de Doença de Alzheimer do IPUB, no Rio de Janeiro. A pesquisa busca apontar demandas em atenção psicossocial e psicogeriátrica dos usuários, além de produzir materiais que possam inspirar práticas semelhantes em outros serviços de saúde mental. Como produto técnico, foi elaborado um fluxograma do serviço de acolhimento. \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Test\n",
    "json_document = retrieve_document(filename_list[120])\n",
    "\n",
    "query = get_research_topic(json_document['title'], json_document['abstract'])\n",
    "\n",
    "print(\"Title:\", json_document['title'], \"\\n\")\n",
    "print(\"Abstract:\", json_document['abstract'], \"\\n\")\n",
    "print(\"Query:\", query, \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Artigos Similares"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recuperando Embeddings...\n",
      "Construindo Vector Database...\n"
     ]
    }
   ],
   "source": [
    "from langchain.vectorstores import FAISS\n",
    "from langchain.embeddings import SentenceTransformerEmbeddings\n",
    "\n",
    "print(\"Recuperando Embeddings...\")\n",
    "embeddings = SentenceTransformerEmbeddings(model_name=\"sentence-transformers/paraphrase-multilingual-mpnet-base-v2\")\n",
    "\n",
    "print(\"Construindo Vector Database...\")\n",
    "vectorstore = FAISS.load_local(\"./faiss_vector_store/\", embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cohere\n",
    "\n",
    "cohere_key = \"xxxxx\"\n",
    "cohere_client = cohere.Client(cohere_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_similar_abstracts(abstract, original_id, k=5, fetch_k=10000):\n",
    "    res = vectorstore.similarity_search_with_score(\n",
    "        abstract,\n",
    "        k=k*2,\n",
    "        fetch_k=fetch_k*2,\n",
    "        filter={\"type\":\"abstract\"}\n",
    "    )\n",
    "    \n",
    "    res = list(set([r[0].metadata['id'] for r in res if (r[0].metadata['id'] != original_id and r[1] < 1.5)]))\n",
    "\n",
    "    # if len(res) == 0:\n",
    "    #     res_reranking = []\n",
    "    # else:\n",
    "    #     reranking_response = cohere_client.rerank(\n",
    "    #       model = \"rerank-multilingual-v2.0\",\n",
    "    #       query = abstract,\n",
    "    #       documents = res,\n",
    "    #       top_n = k-1\n",
    "    #     )\n",
    "    #     res_reranking = [res[r.index] for r in reranking_response if r.relevance_score > 0.5]\n",
    "\n",
    "    return res[:k-1] #, res_reranking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test\n",
    "# get_similar_abstracts(json_document['abstract'], json_document['id'], k=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Execução"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_filename_list = random.sample(filename_list, 100)\n",
    "# sample_filename_list = random.sample(filename_list, 10)       # test sample!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sample_filename_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "....................................................................................................100\n"
     ]
    }
   ],
   "source": [
    "test_info = []\n",
    "\n",
    "for filename in sample_filename_list:\n",
    "    doc = retrieve_document(filename).copy()\n",
    "    \n",
    "    query = get_research_topic(doc['title'], doc['abstract'])\n",
    "    # similar = get_similar_abstracts(doc['abstract'], doc['id'], k=5)\n",
    "   \n",
    "    test_info.append({\n",
    "        \"id\": doc[\"id\"],\n",
    "        \"title\": doc[\"title\"],\n",
    "        \"abstract\": doc[\"abstract\"],\n",
    "        \"query\": query,\n",
    "        # \"similar\": similar,\n",
    "        # \"similar_rerank\": similar_rerank\n",
    "    })\n",
    "    \n",
    "    print('.', end='')\n",
    "    if len(test_info) % 100 == 0: print(len(test_info))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for 1000\n",
    "# started 22:44\n",
    "# ended 23:27"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for info in test_info:\n",
    "#     print(\"title:\", info['title'])\n",
    "#     print(\"query:\", info[\"query\"])\n",
    "#     print(\"similar:\", info[\"similar\"])\n",
    "    # print(\"similar rerank:\", info[\"similar_rerank\"])\n",
    "    # print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Salvamento dos Testes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./validation_tests/2024-06-09\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.mkdir(validation_tests_path)\n",
    "print(validation_tests_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'{validation_tests_path}/test_info.json', 'w') as fp:\n",
    "    json.dump(test_info, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llama",
   "language": "python",
   "name": "llama"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
